# my-tutor-chatbot/app.py

import streamlit as st
import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# --- C·∫§U H√åNH C∆† B·∫¢N ---
# C·∫ßn ph·∫£i ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GOOGLE_API_KEY
if "GOOGLE_API_KEY" not in os.environ:
    st.error("L·ªói: Vui l√≤ng thi·∫øt l·∫≠p GOOGLE_API_KEY trong Streamlit Secrets ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng.")
    st.stop()

# L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn th∆∞ m·ª•c ch·ª©a file app.py
APP_DIR = os.path.dirname(os.path.abspath(__file__))
# N·ªëi ƒë∆∞·ªùng d·∫´n ƒë√≥ v·ªõi th∆∞ m·ª•c "documents"
DOCUMENT_FOLDER = os.path.join(APP_DIR, "documents")


# ---------------------------------------------------------------------
# GIAI ƒêO·∫†N 2 & 3: T·∫¢I, X·ª¨ L√ù, V√Ä THI·∫æT L·∫¨P CHU·ªñI RAG
# S·ª≠ d·ª•ng st.cache_resource ƒë·ªÉ ch·ªâ ch·∫°y h√†m n√†y M·ªòT L·∫¶N khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông
# ---------------------------------------------------------------------

@st.cache_resource
def setup_rag_system():
    """T·∫£i t√†i li·ªáu, t·∫°o vector, v√† thi·∫øt l·∫≠p chu·ªói RAG."""
    st.info("ƒêang kh·ªüi t·∫°o Gia s∆∞: T·∫£i t√†i li·ªáu, t·∫°o embeddings...")

    # 1. Kh·ªüi t·∫°o LLM v√† Embedding Model
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)
    embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

    # 2. T·∫£i t·∫•t c·∫£ T√†i li·ªáu t·ª´ th∆∞ m·ª•c 'documents'
    all_documents = []

    if not os.path.exists(DOCUMENT_FOLDER):
        st.error(f"Th∆∞ m·ª•c t√†i li·ªáu '{DOCUMENT_FOLDER}' kh√¥ng t·ªìn t·∫°i.")
        st.stop()

    for filename in os.listdir(DOCUMENT_FOLDER):
        file_path = os.path.join(DOCUMENT_FOLDER, filename)

        if filename.endswith(".pdf"):
            loader = PyPDFLoader(file_path)
        elif filename.endswith(".docx"):
            loader = Docx2txtLoader(file_path)
        elif filename.endswith(".txt"):
            loader = TextLoader(file_path, encoding="utf-8")
        else:
            continue

        all_documents.extend(loader.load())

    if not all_documents:
        st.warning(f"Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o trong th∆∞ m·ª•c '{DOCUMENT_FOLDER}'.")
        st.stop()

    # 3. Chia ƒëo·∫°n (Chunking) T·ªëi ∆∞u
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=70)
    chunks = text_splitter.split_documents(all_documents)

    # 4. T·∫°o v√† L∆∞u tr·ªØ Vector (d√πng ChromaDB t·∫°m th·ªùi)
    vector_store = Chroma.from_documents(documents=chunks, embedding=embedding_model)
    retriever = vector_store.as_retriever(search_kwargs={"k": 4})  # L·∫•y 4 ƒëo·∫°n li√™n quan nh·∫•t

    # 5. X√¢y d·ª±ng Chu·ªói RAG v·ªõi Prompt Gia s∆∞
    SYSTEM_PROMPT = """
    B·∫°n l√† m·ªôt gia s∆∞ chuy√™n nghi·ªáp, nhi·ªát t√¨nh v√† ki√™n nh·∫´n. Nhi·ªám v·ª• c·ªßa b·∫°n l√†:
    1. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa h·ªçc sinh M·ªòT C√ÅCH CH√çNH X√ÅC, D·ª∞A TR√äN N·ªòI DUNG T√ÄI LI·ªÜU ƒë∆∞·ª£c cung c·∫•p b√™n d∆∞·ªõi.
    2. Gi·∫£i th√≠ch c√°c kh√°i ni·ªám m·ªôt c√°ch d·ªÖ hi·ªÉu.
    3. Sau m·ªói c√¢u tr·∫£ l·ªùi, h√£y ƒê·∫∂T M·ªòT C√ÇU H·ªéI NG·∫ÆN G·ªåN ƒë·ªÉ ki·ªÉm tra s·ª± hi·ªÉu bi·∫øt.

    N·ªôi dung t√†i li·ªáu tham kh·∫£o:
    ----------------
    {context}
    ----------------
    """

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", SYSTEM_PROMPT),
            ("human", "{input}"),
        ]
    )

    document_chain = create_stuff_documents_chain(llm, prompt)
    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    st.success(f"Kh·ªüi t·∫°o ho√†n t·∫•t. ƒê√£ x·ª≠ l√Ω {len(chunks)} ƒëo·∫°n ki·∫øn th·ª©c.")
    return retrieval_chain


# --- ·ª®NG D·ª§NG STREAMLIT CH√çNH (GIAI ƒêO·∫†N 4) ---

st.title("üë®‚Äçüè´ Chatbot Gia S∆∞ C√° Nh√¢n")
st.caption("S·ª≠ d·ª•ng Gemini API v√† RAG ƒë·ªÉ tr·∫£ l·ªùi d·ª±a tr√™n t√†i li·ªáu c·ªßa b·∫°n.")

# Kh·ªüi t·∫°o RAG System (ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = setup_rag_system()

# L·∫•y chu·ªói RAG ƒë√£ t·∫°o
retrieval_chain = st.session_state.rag_chain

# Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
if "messages" not in st.session_state:
    st.session_state.messages = []

# Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# X·ª≠ l√Ω input c·ªßa ng∆∞·ªùi d√πng
if prompt := st.chat_input("H·ªèi gia s∆∞ c·ªßa b·∫°n m·ªôt c√¢u h·ªèi..."):
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # G·ªçi RAG Chain ƒë·ªÉ l·∫•y c√¢u tr·∫£ l·ªùi
    with st.chat_message("assistant"):
        with st.spinner("Gia s∆∞ ƒëang t√¨m ki·∫øm v√† tr·∫£ l·ªùi..."):
            try:
                # G·ªçi chu·ªói RAG
                response = retrieval_chain.invoke({"input": prompt})
                answer = response["answer"]

                # Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi v√† th√™m v√†o l·ªãch s·ª≠
                st.markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})

            except Exception as e:
                error_message = f"C√≥ l·ªói x·∫£y ra khi g·ªçi API: {e}"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
